{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44baa34d-19da-444f-a623-5a7c05a8f31f",
   "metadata": {},
   "source": [
    "# Part 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c1c5b5c-2a84-4a64-95e1-8393f0dff64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher model:\n",
      "0.9437999725341797\n",
      "0.9633999466896057\n",
      "0.973099946975708\n",
      "0.9765999913215637\n",
      "0.9776999950408936\n",
      "Student model:\n",
      "0.8533999919891357\n",
      "0.8914999961853027\n",
      "0.904699981212616\n",
      "0.910099983215332\n",
      "0.9138000011444092\n",
      "ditillation:\n",
      "0.8525999784469604\n",
      "0.8885999917984009\n",
      "0.8994999527931213\n",
      "0.9061999917030334\n",
      "0.9102999567985535\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import pandas\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The network is referenced from https://arxiv.org/pdf/1503.02531v1.pdf\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "learning_rate=0.0001\n",
    "torch.manual_seed(0)\n",
    "\n",
    "temp = 3\n",
    "drop_out = 0.3\n",
    "beta = 0.5\n",
    "batchSize = 32\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "train_dataset = torchvision.datasets.MNIST(root=\"mnist_dataset/\",train=True,transform=transforms.ToTensor(),download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"mnist_dataset/\",train=False,transform=transforms.ToTensor(),download=True)\n",
    "\n",
    "\n",
    "\n",
    "class TeacherModel(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(TeacherModel, self).__init__()\n",
    "        self.full_connect1 = nn.Linear(784, 1200)\n",
    "        self.full_connect2 = nn.Linear(1200, 1200)\n",
    "        self.full_connect3 = nn.Linear(1200, 10)\n",
    "        self.dt = nn.Dropout(drop_out)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.full_connect1(x)\n",
    "        x = self.dt(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.full_connect2(x)\n",
    "        x = self.dt(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.full_connect3(x)\n",
    "        return x  \n",
    "\n",
    "\n",
    "class StudentModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentModel, self).__init__()\n",
    "        self.full_connect1 = nn.Linear(784,15)\n",
    "        self.full_connect2 = nn.Linear(15, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.full_connect1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.full_connect2(x)\n",
    "        return x  \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchSize, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batchSize, shuffle=False)\n",
    "\n",
    "def getAcc(target_model):\n",
    "    corr = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            preds = target_model(x)\n",
    "            predictions = preds.max(1).indices\n",
    "            corr += (predictions == y).sum()\n",
    "            total += predictions.size(0)\n",
    "        acc = (torch.true_divide(corr,total)).item()\n",
    "        print(acc)\n",
    "        target_model.train()\n",
    "    return target_model\n",
    "\n",
    "def execute(epochs,target_model):\n",
    "    for epoch in range(0,epochs):\n",
    "        target_model.train()\n",
    "        for data, targets in train_loader:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            preds = target_model(data)\n",
    "            loss = criterion(preds, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        target_model.eval()\n",
    "        target_model=getAcc(target_model)\n",
    "        \n",
    "        \n",
    "    return target_model.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "teacher_model = TeacherModel()\n",
    "teacher_model = teacher_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(teacher_model.parameters(), lr=learning_rate)\n",
    "print(\"Teacher model:\")\n",
    "teacher_model=execute(5,teacher_model)\n",
    "\n",
    "student_model = StudentModel()\n",
    "student_model = student_model.to(device)\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(\"Student model:\")\n",
    "student_model=execute(5,student_model)\n",
    "\n",
    "student_model = StudentModel()\n",
    "student_model = student_model.to(device)\n",
    "student_model.train()\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=learning_rate)\n",
    "soft_loss = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "hard_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "print(\"ditillation:\")\n",
    "for epoch in range(0,5):\n",
    "    for data, targets in train_loader:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        with torch.no_grad():\n",
    "            teacher_preds = teacher_model(data)\n",
    "        student_preds = student_model(data)\n",
    "        student_loss = hard_loss(student_preds, targets)\n",
    "        ditillation_loss = soft_loss(\n",
    "            F.softmax(student_preds / temp, dim=1),\n",
    "            F.softmax(teacher_preds / temp, dim=1)\n",
    "        )\n",
    "        loss = (1 - beta) * student_loss + beta * ditillation_loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    student_model.eval()\n",
    "    student_model=getAcc(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e71c6c7a-96a2-4583-b554-8f832659d0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher model:\n",
      "0.9437999725341797\n",
      "0.9633999466896057\n",
      "0.973099946975708\n",
      "0.9765999913215637\n",
      "0.9776999950408936\n",
      "Student model:\n",
      "0.8533999919891357\n",
      "0.8914999961853027\n",
      "0.904699981212616\n",
      "0.910099983215332\n",
      "0.9138000011444092\n",
      "ditillation:\n",
      "0.8551999926567078\n",
      "0.8913999795913696\n",
      "0.902999997138977\n",
      "0.9090999960899353\n",
      "0.91239994764328\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import pandas\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The network is referenced from https://arxiv.org/pdf/1503.02531v1.pdf\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "learning_rate=0.0001\n",
    "torch.manual_seed(0)\n",
    "\n",
    "temp = 5\n",
    "drop_out = 0.3\n",
    "beta = 0.5\n",
    "batchSize = 32\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "train_dataset = torchvision.datasets.MNIST(root=\"mnist_dataset/\",train=True,transform=transforms.ToTensor(),download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"mnist_dataset/\",train=False,transform=transforms.ToTensor(),download=True)\n",
    "\n",
    "\n",
    "\n",
    "class TeacherModel(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(TeacherModel, self).__init__()\n",
    "        self.full_connect1 = nn.Linear(784, 1200)\n",
    "        self.full_connect2 = nn.Linear(1200, 1200)\n",
    "        self.full_connect3 = nn.Linear(1200, 10)\n",
    "        self.dt = nn.Dropout(drop_out)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.full_connect1(x)\n",
    "        x = self.dt(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.full_connect2(x)\n",
    "        x = self.dt(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.full_connect3(x)\n",
    "        return x  \n",
    "\n",
    "\n",
    "class StudentModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentModel, self).__init__()\n",
    "        self.full_connect1 = nn.Linear(784,15)\n",
    "        self.full_connect2 = nn.Linear(15, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.full_connect1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.full_connect2(x)\n",
    "        return x  \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchSize, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batchSize, shuffle=False)\n",
    "\n",
    "def getAcc(target_model):\n",
    "    corr = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            preds = target_model(x)\n",
    "            predictions = preds.max(1).indices\n",
    "            corr += (predictions == y).sum()\n",
    "            total += predictions.size(0)\n",
    "        acc = (torch.true_divide(corr,total)).item()\n",
    "        print(acc)\n",
    "        target_model.train()\n",
    "    return target_model\n",
    "\n",
    "def execute(epochs,target_model):\n",
    "    for epoch in range(0,epochs):\n",
    "        target_model.train()\n",
    "        for data, targets in train_loader:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            preds = target_model(data)\n",
    "            loss = criterion(preds, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        target_model.eval()\n",
    "        target_model=getAcc(target_model)\n",
    "        \n",
    "        \n",
    "    return target_model.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "teacher_model = TeacherModel()\n",
    "teacher_model = teacher_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(teacher_model.parameters(), lr=learning_rate)\n",
    "print(\"Teacher model:\")\n",
    "teacher_model=execute(5,teacher_model)\n",
    "\n",
    "student_model = StudentModel()\n",
    "student_model = student_model.to(device)\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(\"Student model:\")\n",
    "student_model=execute(5,student_model)\n",
    "\n",
    "student_model = StudentModel()\n",
    "student_model = student_model.to(device)\n",
    "student_model.train()\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=learning_rate)\n",
    "soft_loss = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "hard_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "print(\"ditillation:\")\n",
    "for epoch in range(0,5):\n",
    "    for data, targets in train_loader:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        with torch.no_grad():\n",
    "            teacher_preds = teacher_model(data)\n",
    "        student_preds = student_model(data)\n",
    "        student_loss = hard_loss(student_preds, targets)\n",
    "        ditillation_loss = soft_loss(\n",
    "            F.softmax(student_preds / temp, dim=1),\n",
    "            F.softmax(teacher_preds / temp, dim=1)\n",
    "        )\n",
    "        loss = (1 - beta) * student_loss + beta * ditillation_loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    student_model.eval()\n",
    "    student_model=getAcc(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89b79ca1-7673-48a9-869a-79ac1aac990a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher model:\n",
      "0.9437999725341797\n",
      "0.9633999466896057\n",
      "0.973099946975708\n",
      "0.9765999913215637\n",
      "0.9776999950408936\n",
      "Student model:\n",
      "0.8533999919891357\n",
      "0.8914999961853027\n",
      "0.904699981212616\n",
      "0.910099983215332\n",
      "0.9138000011444092\n",
      "ditillation:\n",
      "0.8562999963760376\n",
      "0.8919000029563904\n",
      "0.9050999879837036\n",
      "0.9106000065803528\n",
      "0.9161999821662903\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import pandas\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The network is referenced from https://arxiv.org/pdf/1503.02531v1.pdf\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "learning_rate=0.0001\n",
    "torch.manual_seed(0)\n",
    "\n",
    "temp = 10\n",
    "drop_out = 0.3\n",
    "beta = 0.5\n",
    "batchSize = 32\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "train_dataset = torchvision.datasets.MNIST(root=\"mnist_dataset/\",train=True,transform=transforms.ToTensor(),download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"mnist_dataset/\",train=False,transform=transforms.ToTensor(),download=True)\n",
    "\n",
    "\n",
    "\n",
    "class TeacherModel(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(TeacherModel, self).__init__()\n",
    "        self.full_connect1 = nn.Linear(784, 1200)\n",
    "        self.full_connect2 = nn.Linear(1200, 1200)\n",
    "        self.full_connect3 = nn.Linear(1200, 10)\n",
    "        self.dt = nn.Dropout(drop_out)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.full_connect1(x)\n",
    "        x = self.dt(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.full_connect2(x)\n",
    "        x = self.dt(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.full_connect3(x)\n",
    "        return x  \n",
    "\n",
    "\n",
    "class StudentModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentModel, self).__init__()\n",
    "        self.full_connect1 = nn.Linear(784,15)\n",
    "        self.full_connect2 = nn.Linear(15, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.full_connect1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.full_connect2(x)\n",
    "        return x  \n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchSize, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batchSize, shuffle=False)\n",
    "\n",
    "def getAcc(target_model):\n",
    "    corr = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            preds = target_model(x)\n",
    "            predictions = preds.max(1).indices\n",
    "            corr += (predictions == y).sum()\n",
    "            total += predictions.size(0)\n",
    "        acc = (torch.true_divide(corr,total)).item()\n",
    "        print(acc)\n",
    "        target_model.train()\n",
    "    return target_model\n",
    "\n",
    "def execute(epochs,target_model):\n",
    "    for epoch in range(0,epochs):\n",
    "        target_model.train()\n",
    "        for data, targets in train_loader:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            preds = target_model(data)\n",
    "            loss = criterion(preds, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        target_model.eval()\n",
    "        target_model=getAcc(target_model)\n",
    "        \n",
    "        \n",
    "    return target_model.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "teacher_model = TeacherModel()\n",
    "teacher_model = teacher_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(teacher_model.parameters(), lr=learning_rate)\n",
    "print(\"Teacher model:\")\n",
    "teacher_model=execute(5,teacher_model)\n",
    "\n",
    "student_model = StudentModel()\n",
    "student_model = student_model.to(device)\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(\"Student model:\")\n",
    "student_model=execute(5,student_model)\n",
    "\n",
    "student_model = StudentModel()\n",
    "student_model = student_model.to(device)\n",
    "student_model.train()\n",
    "optimizer = torch.optim.Adam(student_model.parameters(), lr=learning_rate)\n",
    "soft_loss = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "hard_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "print(\"ditillation:\")\n",
    "for epoch in range(0,5):\n",
    "    for data, targets in train_loader:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        with torch.no_grad():\n",
    "            teacher_preds = teacher_model(data)\n",
    "        student_preds = student_model(data)\n",
    "        student_loss = hard_loss(student_preds, targets)\n",
    "        ditillation_loss = soft_loss(\n",
    "            F.softmax(student_preds / temp, dim=1),\n",
    "            F.softmax(teacher_preds / temp, dim=1)\n",
    "        )\n",
    "        loss = (1 - beta) * student_loss + beta * ditillation_loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    student_model.eval()\n",
    "    student_model=getAcc(student_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25592bb3-cda1-436c-8393-bca3f67538c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
