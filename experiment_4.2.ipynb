{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0908cb8-9435-4b47-86ca-ca3955a2511f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e998d4f9-d323-4e60-afa7-699bbc15fa07",
   "metadata": {},
   "source": [
    "## Train ResNet18 from scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e592e6b9-dd31-4f45-ab29-0dbd6159d716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenpuquan/anaconda3/envs/distill/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 170498071/170498071 [18:47<00:00, 151152.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenpuquan/anaconda3/envs/distill/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/chenpuquan/anaconda3/envs/distill/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved best model\n",
      "epoch: 0 \n",
      "Train Loss: 3.5744 \n",
      "Eval Loss: 4.2687 \n",
      "Train Acc: 0.3180 \n",
      "Eval Acc: 0.1023\n",
      "saved best model\n",
      "epoch: 1 \n",
      "Train Loss: 1.4986 \n",
      "Eval Loss: 2.3429 \n",
      "Train Acc: 0.5005 \n",
      "Eval Acc: 0.3024\n",
      "saved best model\n",
      "epoch: 2 \n",
      "Train Loss: 1.2096 \n",
      "Eval Loss: 1.3176 \n",
      "Train Acc: 0.5789 \n",
      "Eval Acc: 0.5410\n",
      "saved best model\n",
      "epoch: 3 \n",
      "Train Loss: 1.0223 \n",
      "Eval Loss: 1.2442 \n",
      "Train Acc: 0.6429 \n",
      "Eval Acc: 0.5622\n",
      "epoch: 4 \n",
      "Train Loss: 0.8429 \n",
      "Eval Loss: 1.3224 \n",
      "Train Acc: 0.7104 \n",
      "Eval Acc: 0.5529\n",
      "saved best model\n",
      "epoch: 5 \n",
      "Train Loss: 0.6647 \n",
      "Eval Loss: 1.3066 \n",
      "Train Acc: 0.7773 \n",
      "Eval Acc: 0.5751\n",
      "epoch: 6 \n",
      "Train Loss: 0.4735 \n",
      "Eval Loss: 1.4742 \n",
      "Train Acc: 0.8476 \n",
      "Eval Acc: 0.5586\n",
      "saved best model\n",
      "epoch: 7 \n",
      "Train Loss: 0.3080 \n",
      "Eval Loss: 1.5337 \n",
      "Train Acc: 0.9075 \n",
      "Eval Acc: 0.5767\n",
      "epoch: 8 \n",
      "Train Loss: 0.1843 \n",
      "Eval Loss: 1.7560 \n",
      "Train Acc: 0.9492 \n",
      "Eval Acc: 0.5584\n",
      "epoch: 9 \n",
      "Train Loss: 0.1036 \n",
      "Eval Loss: 1.8243 \n",
      "Train Acc: 0.9761 \n",
      "Eval Acc: 0.5681\n",
      "saved best model\n",
      "epoch: 10 \n",
      "Train Loss: 0.0530 \n",
      "Eval Loss: 1.9047 \n",
      "Train Acc: 0.9916 \n",
      "Eval Acc: 0.5782\n",
      "saved best model\n",
      "epoch: 11 \n",
      "Train Loss: 0.0265 \n",
      "Eval Loss: 1.9040 \n",
      "Train Acc: 0.9972 \n",
      "Eval Acc: 0.5852\n",
      "saved best model\n",
      "epoch: 12 \n",
      "Train Loss: 0.0130 \n",
      "Eval Loss: 1.9510 \n",
      "Train Acc: 0.9994 \n",
      "Eval Acc: 0.5878\n",
      "saved best model\n",
      "epoch: 13 \n",
      "Train Loss: 0.0069 \n",
      "Eval Loss: 1.9693 \n",
      "Train Acc: 0.9999 \n",
      "Eval Acc: 0.5920\n",
      "epoch: 14 \n",
      "Train Loss: 0.0043 \n",
      "Eval Loss: 1.9883 \n",
      "Train Acc: 1.0000 \n",
      "Eval Acc: 0.5907\n",
      "saved best model\n",
      "epoch: 15 \n",
      "Train Loss: 0.0030 \n",
      "Eval Loss: 2.0055 \n",
      "Train Acc: 1.0000 \n",
      "Eval Acc: 0.5934\n",
      "saved best model\n",
      "epoch: 16 \n",
      "Train Loss: 0.0024 \n",
      "Eval Loss: 2.0199 \n",
      "Train Acc: 1.0000 \n",
      "Eval Acc: 0.5946\n",
      "epoch: 17 \n",
      "Train Loss: 0.0020 \n",
      "Eval Loss: 2.0369 \n",
      "Train Acc: 1.0000 \n",
      "Eval Acc: 0.5926\n",
      "epoch: 18 \n",
      "Train Loss: 0.0018 \n",
      "Eval Loss: 2.0473 \n",
      "Train Acc: 1.0000 \n",
      "Eval Acc: 0.5930\n",
      "epoch: 19 \n",
      "Train Loss: 0.0016 \n",
      "Eval Loss: 2.0668 \n",
      "Train Acc: 1.0000 \n",
      "Eval Acc: 0.5905\n",
      "epoch: 20 \n",
      "Train Loss: 0.0015 \n",
      "Eval Loss: 2.0749 \n",
      "Train Acc: 1.0000 \n",
      "Eval Acc: 0.5916\n",
      "epoch: 21 \n",
      "Train Loss: 0.0014 \n",
      "Eval Loss: 2.0919 \n",
      "Train Acc: 1.0000 \n",
      "Eval Acc: 0.5926\n",
      "epoch: 22 \n",
      "Train Loss: 0.0012 \n",
      "Eval Loss: 2.1021 \n",
      "Train Acc: 1.0000 \n",
      "Eval Acc: 0.5910\n",
      "epoch: 23 \n",
      "Train Loss: 0.0011 \n",
      "Eval Loss: 2.1130 \n",
      "Train Acc: 1.0000 \n",
      "Eval Acc: 0.5912\n",
      "epoch: 24 \n",
      "Train Loss: 0.0011 \n",
      "Eval Loss: 2.1262 \n",
      "Train Acc: 1.0000 \n",
      "Eval Acc: 0.5911\n",
      "epoch: 25 \n",
      "Train Loss: 0.0010 \n",
      "Eval Loss: 2.1297 \n",
      "Train Acc: 1.0000 \n",
      "Eval Acc: 0.5915\n",
      "epoch: 26 \n",
      "Train Loss: 0.0009 \n",
      "Eval Loss: 2.1387 \n",
      "Train Acc: 1.0000 \n",
      "Eval Acc: 0.5927\n",
      "epoch: 27 \n",
      "Train Loss: 0.0009 \n",
      "Eval Loss: 2.1526 \n",
      "Train Acc: 1.0000 \n",
      "Eval Acc: 0.5913\n",
      "epoch: 28 \n",
      "Train Loss: 0.0008 \n",
      "Eval Loss: 2.1577 \n",
      "Train Acc: 1.0000 \n",
      "Eval Acc: 0.5906\n",
      "epoch: 29 \n",
      "Train Loss: 0.0008 \n",
      "Eval Loss: 2.1700 \n",
      "Train Acc: 1.0000 \n",
      "Eval Acc: 0.5911\n"
     ]
    }
   ],
   "source": [
    "#Resnet18 without pretrain\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "EPOCH = 30              \n",
    "BATCH_SIZE = 2048         \n",
    "\n",
    "\n",
    "# CIFAR10 Datasets download\n",
    "train_data = datasets.CIFAR10(root='./data',\n",
    "                         train=True,                         \n",
    "                         transform=transforms.ToTensor(),    \n",
    "                         download=True\n",
    "                        )\n",
    "\n",
    "test_data = datasets.CIFAR10(root='./data',\n",
    "                        train=False,                         \n",
    "                        transform=transforms.ToTensor(),     \n",
    "                        download=True\n",
    "                        )\n",
    "\n",
    "# use dataloader to load the dataset\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# ResNet18 without pretrain weight\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# setting adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
    "\n",
    "#device : GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device) \n",
    "Total_acc = 0\n",
    "\n",
    "\n",
    "# start training\n",
    "for epoch in range(EPOCH):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.train()\n",
    "    \n",
    "    for i, data in enumerate(train_loader, start=0):\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # forward propagation\n",
    "        outputs = model(inputs)\n",
    "        # caculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # clear gradient \n",
    "        optimizer.zero_grad()\n",
    "        # back pro\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        num_correct = (predicted == labels).sum().item()\n",
    "        acc = num_correct / inputs.shape[0]\n",
    "        train_acc += acc\n",
    "\n",
    "    model.eval() # change to eval mode\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # forward propagation\n",
    "        out = model(images)\n",
    "        loss = criterion(out, labels)\n",
    "        eval_loss += loss.item()\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        num_correct = (predicted == labels).sum().item()\n",
    "        acc = num_correct / images.shape[0]\n",
    "        eval_acc += acc\n",
    "    \n",
    "    # save best model\n",
    "    if eval_acc > Total_acc:\n",
    "        torch.save(model, 'cifar10_resnet18_scratch.pt')\n",
    "        print(\"saved best model\")\n",
    "        Total_acc = eval_acc\n",
    "        \n",
    "    # print the result\n",
    "    print('epoch: {} \\nTrain Loss: {:.4f} \\nEval Loss: {:.4f} \\nTrain Acc: {:.4f} \\nEval Acc: {:.4f}'\n",
    "          .format(epoch, \n",
    "                  train_loss / len(train_loader), \n",
    "                  eval_loss / len(test_loader), \n",
    "                  train_acc / len(train_loader),\n",
    "                  eval_acc / len(test_loader)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e38f4e-ef2b-4f51-a139-7187a0c9918d",
   "metadata": {},
   "source": [
    "## Train ResNet50 with pretrained weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6002d45c-0ba9-446c-b634-7ab666105afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resnet50 with pretrain\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# hyperparameters setting\n",
    "EPOCH = 30              \n",
    "BATCH_SIZE = 2048         \n",
    "\n",
    "resnet50_train_losses = []\n",
    "resnet50_train_acces = []\n",
    "resnet50_eval_losses = []\n",
    "resnet50_eval_acces = []\n",
    "\n",
    "# CIFAR10 Datasets download\n",
    "train_data = datasets.CIFAR10(root='./data',\n",
    "                         train=True,                         \n",
    "                         transform=transforms.ToTensor(),    \n",
    "                         download=True\n",
    "                        )\n",
    "\n",
    "test_data = datasets.CIFAR10(root='./data',\n",
    "                        train=False,                         \n",
    "                        transform=transforms.ToTensor(),     \n",
    "                        download=True\n",
    "                        )\n",
    "\n",
    "# use dataloader to load the dataset\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# ResNet50 with pretrain weight\n",
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# setting adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "#device : GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device) \n",
    "Total_acc = 0\n",
    "\n",
    "\n",
    "# start training\n",
    "for epoch in range(EPOCH):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    model.train()\n",
    "    \n",
    "    for i, data in enumerate(train_loader, start=0):\n",
    "\n",
    "        inputs, labels = data\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # forward propagation\n",
    "        outputs = model(inputs)\n",
    "        # caculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # clear gradient \n",
    "        optimizer.zero_grad()\n",
    "        # back pro\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        num_correct = (predicted == labels).sum().item()\n",
    "        acc = num_correct / inputs.shape[0]\n",
    "        train_acc += acc\n",
    "\n",
    "    resnet50_train_losses.append(train_loss / len(train_loader))\n",
    "    resnet50_train_acces.append(train_acc / len(train_loader))\n",
    "\n",
    "    model.eval() # change to eval mode\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # forward propagation\n",
    "        out = model(images)\n",
    "        loss = criterion(out, labels)\n",
    "        eval_loss += loss.item()\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        num_correct = (predicted == labels).sum().item()\n",
    "        acc = num_correct / images.shape[0]\n",
    "        eval_acc += acc\n",
    "    \n",
    "    resnet50_eval_losses.append(eval_loss/len(test_loader))\n",
    "    resnet50_eval_acces.append((eval_acc/len(test_loader)))\n",
    "    \n",
    "    # save best model\n",
    "    if eval_acc > Total_acc:\n",
    "        torch.save(model, 'cifar10_resnet50.pt')\n",
    "        print(\"saved best model\")\n",
    "        Total_acc = eval_acc\n",
    "        \n",
    "    # print the result\n",
    "    print('epoch: {} \\nTrain Loss: {:.4f} \\nEval Loss: {:.4f} \\nTrain Acc: {:.4f} \\nEval Acc: {:.4f}'\n",
    "          .format(epoch, \n",
    "                  train_loss / len(train_loader), \n",
    "                  eval_loss / len(test_loader), \n",
    "                  train_acc / len(train_loader),\n",
    "                  eval_acc / len(test_loader)))\n",
    "\n",
    "    \n",
    "# save data to csv file\n",
    "array = [resnet50_train_losses,resnet50_train_acces,resnet50_eval_losses,resnet50_eval_acces]\n",
    "df = pd.DataFrame(array,index = ['train_losses', 'train_acces','eval_losses','eval_acces'])\n",
    "df.to_csv('./resnet50.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758ddd29-02b7-42e3-a2c5-c2c6d84bf5ce",
   "metadata": {},
   "source": [
    "## Evaluation with test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7353ad-9a2a-4772-bf15-986a3640a709",
   "metadata": {},
   "source": [
    "This part of code can be use for multiple evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10638e82-f81f-44d0-8968-0e777e25f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalution with test set\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "test_data = datasets.CIFAR10(root='./data',\n",
    "                        train=False,                         \n",
    "                        transform=transforms.ToTensor(),     \n",
    "                        download=True\n",
    "                        )\n",
    "\n",
    "BATCH_SIZE=2048\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "model = torch.load('drive/My Drive/9417/resnet18-vgg16/distill_resnet18_resnet50_T=3b=0.5.pt')  # change this line to evaluate diffrent models\n",
    "model.eval() #change to eval mode\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for data in test_loader:\n",
    "    images, labels = data\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    out = model(images)\n",
    "    \n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print the testing result\n",
    "print('Accuracy:{:.4f}%'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2900f8ef-a2d6-4ec4-877b-c5279f6466a7",
   "metadata": {},
   "source": [
    "## Train ResNet18 using knowledge distillation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6f2a873-4734-4b2d-b83c-07127769f97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now Trying: T = 3, beta = 0.5\n",
      "saved best model\n",
      "epoch: 0 \n",
      "Train Loss: 8.9219 \n",
      "Eval Loss: 4.7406 \n",
      "Train Acc: 0.3974 \n",
      "Eval Acc: 0.1424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenpuquan/anaconda3/envs/distill/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/chenpuquan/anaconda3/envs/distill/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now Trying: T = 3, beta = 0.7\n",
      "saved best model\n",
      "epoch: 0 \n",
      "Train Loss: 11.4122 \n",
      "Eval Loss: 4.5720 \n",
      "Train Acc: 0.3924 \n",
      "Eval Acc: 0.1705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenpuquan/anaconda3/envs/distill/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/chenpuquan/anaconda3/envs/distill/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now Trying: T = 5, beta = 0.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     98\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 100\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(student_outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    103\u001b[0m num_correct \u001b[38;5;241m=\u001b[39m (predicted \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "soft_loss = torch.nn.KLDivLoss(reduction=\"batchmean\") \n",
    "hard_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCH = 85              \n",
    "BATCH_SIZE = 2048         \n",
    "\n",
    "temperature_list = [3, 5, 7, 10]\n",
    "beta_list = [0.5,0.7]\n",
    "\n",
    "for temp in temperature_list:\n",
    "  \n",
    "    for beta in beta_list:\n",
    "\n",
    "\n",
    "        distill_resnet18_train_losses = []\n",
    "        distill_resnet18_train_acces = []\n",
    "        distill_resnet18_eval_losses = []\n",
    "        distill_resnet18_eval_acces = []\n",
    "\n",
    "        # load the teacher model\n",
    "        teacher_model = torch.load('cifar10_resnet50_pretrain.pt') # you can access this model from https://drive.google.com/file/d/17zYxp_FfcVrkRd3UJb-uakfc4ddME0gA/view?usp=sharing\n",
    "        teacher_model.eval() # use teacher model to produce soft targets \n",
    "\n",
    "        student_model = torchvision.models.resnet18(pretrained=False)\n",
    "        \n",
    "        train_data = datasets.CIFAR10(root='./data',\n",
    "                                train=True,                        \n",
    "                                transform=transforms.ToTensor(),    \n",
    "                                download=False\n",
    "                                )\n",
    "\n",
    "        test_data = datasets.CIFAR10(root='./data',\n",
    "                                train=False,                         \n",
    "                                transform=transforms.ToTensor(),     \n",
    "                                download=False\n",
    "                                )\n",
    "\n",
    "        # contruct dataloader\n",
    "        train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    " \n",
    "        # optimizer\n",
    "        optimizer = optim.Adam(student_model.parameters(), lr=2e-3)\n",
    "\n",
    "        #device : GPU or CPU\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        student_model.to(device) #将模型加载到相应设备中\n",
    "\n",
    "\n",
    "        print(\"Now Trying: T = {}, beta = {}\".format(temp,beta))\n",
    "\n",
    "        Total_acc = 0.0  \n",
    "        for epoch in range(EPOCH):\n",
    "            train_loss = 0\n",
    "            train_acc = 0\n",
    "            student_model.train()\n",
    "\n",
    "            for i, data in enumerate(train_loader, start=0):\n",
    "                 \n",
    "                inputs, labels = data\n",
    "                    \n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs = teacher_model(inputs)\n",
    "\n",
    "                # using student model to produce hard targets\n",
    "                student_outputs = student_model(inputs)\n",
    "                \n",
    "                # calculate hard loss\n",
    "                student_loss = hard_loss(student_outputs, labels)\n",
    "                \n",
    "                # procduce soft loss\n",
    "                distillation_loss = F.kl_div(F.log_softmax(student_outputs / temp, dim=1), F.softmax(teacher_outputs / temp, dim=1), reduction='batchmean') * temp * temp\n",
    "                \n",
    "                # combine soft loss and hard loss \n",
    "                loss = (1 - beta) * student_loss + beta * distillation_loss\n",
    "\n",
    "                  \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # back propagation\n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(student_outputs.data, 1)\n",
    "                num_correct = (predicted == labels).sum().item()\n",
    "                acc = num_correct / inputs.shape[0]\n",
    "                train_acc += acc\n",
    "\n",
    "\n",
    "        distill_resnet18_train_losses.append(train_loss / len(train_loader))\n",
    "        distill_resnet18_train_acces.append(train_acc / len(train_loader))\n",
    "\n",
    "        student_model.eval() # evaluation \n",
    "        eval_loss = 0\n",
    "        eval_acc = 0\n",
    "\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            out = student_model(images)\n",
    "            loss = hard_loss(out, labels)\n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            num_correct = (predicted == labels).sum().item()\n",
    "            acc = num_correct / images.shape[0]\n",
    "            eval_acc += acc\n",
    "\n",
    "\n",
    "        distill_resnet18_eval_losses.append(eval_loss/len(test_loader))\n",
    "        distill_resnet18_eval_acces.append((eval_acc/len(test_loader)))\n",
    "        \n",
    "        # save best model\n",
    "        if eval_acc > Total_acc:\n",
    "            torch.save(student_model, './distill_resnet18_fromResNet50_T={}b={}.pt'.format(temp,beta)) # you can change this line to set another save directory \n",
    "            print(\"saved best model\")\n",
    "            Total_acc = eval_acc\n",
    "\n",
    "        print('epoch: {} \\nTrain Loss: {:.4f} \\nEval Loss: {:.4f} \\nTrain Acc: {:.4f} \\nEval Acc: {:.4f}'\n",
    "                    .format(epoch, \n",
    "                    train_loss / len(train_loader), \n",
    "                    eval_loss / len(test_loader), \n",
    "                    train_acc / len(train_loader),\n",
    "                    eval_acc / len(test_loader)))\n",
    "        \n",
    "        \n",
    "        # save record to csv file\n",
    "        array = [distill_resnet18_train_losses,distill_resnet18_train_acces,distill_resnet18_eval_losses,distill_resnet18_eval_acces]\n",
    "        df = pd.DataFrame(array,index = ['train_losses', 'train_acces','eval_losses','eval_acces'])\n",
    "        df.to_csv('./distill_resnet18-ResNet50_T={}beta={}.csv'.format(temp,beta)) # you can change this line to set another save directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d92196-deeb-4546-8aa5-8e70f8e516e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
